====> Test set loss: 543.8400
====> Test set loss: 543.8329
====> Test set loss: 543.8327
====> Test set loss: 543.8326
====> Test set loss: 543.8325
OrderedDict([('1.weight', tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]])), ('1.bias', tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1])), ('3.weight', tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]])), ('3.bias', tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))])
====> Test set loss: 543.8437
OrderedDict([('1.weight', tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]])), ('1.bias', tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1])), ('3.weight', tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]])), ('3.bias', tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))])
====> Test set loss: 543.8366
OrderedDict([('1.weight', tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]])), ('1.bias', tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1])), ('3.weight', tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]])), ('3.bias', tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))])
====> Test set loss: 543.8364
OrderedDict([('1.weight', tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]])), ('1.bias', tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1])), ('3.weight', tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]])), ('3.bias', tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))])
====> Test set loss: 543.8363
OrderedDict([('1.weight', tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]])), ('1.bias', tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1])), ('3.weight', tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]])), ('3.bias', tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))])
====> Test set loss: 543.8362
Train Epoch: 0 [0/6000 (0%)]	Loss: 543.832886	BCE:543.7509	KLD:0.0770	C_loss:0.0051
Train Epoch: 0 [640/6000 (11%)]	Loss: 418.959686	BCE:418.8939	KLD:0.0617	C_loss:0.0041
Train Epoch: 0 [1280/6000 (21%)]	Loss: 368.949890	BCE:368.8839	KLD:0.0624	C_loss:0.0036
Train Epoch: 0 [1920/6000 (32%)]	Loss: 338.303497	BCE:338.2331	KLD:0.0682	C_loss:0.0022
Train Epoch: 0 [2560/6000 (43%)]	Loss: 270.002777	BCE:269.9156	KLD:0.0846	C_loss:0.0026
Train Epoch: 0 [3200/6000 (53%)]	Loss: 237.390701	BCE:237.2762	KLD:0.1128	C_loss:0.0017
Train Epoch: 0 [3840/6000 (64%)]	Loss: 211.649857	BCE:211.5189	KLD:0.1296	C_loss:0.0014
Train Epoch: 0 [4480/6000 (74%)]	Loss: 200.806686	BCE:200.5912	KLD:0.2139	C_loss:0.0016
Train Epoch: 0 [5120/6000 (85%)]	Loss: 186.922684	BCE:186.8265	KLD:0.0947	C_loss:0.0015
Train Epoch: 0 [5760/6000 (96%)]	Loss: 191.020584	BCE:190.7344	KLD:0.2852	C_loss:0.0010
====> Epoch: 0 Average loss: 290.4207	Classifier Accuracy: 76.5348
====> Test set loss: 195.2110
Train Epoch: 0 [0/6000 (0%)]	Loss: 193.005692	BCE:192.7142	KLD:0.2836	C_loss:0.0079
Train Epoch: 0 [640/6000 (11%)]	Loss: 207.430740	BCE:207.3437	KLD:0.0847	C_loss:0.0024
Train Epoch: 0 [1280/6000 (21%)]	Loss: 200.922806	BCE:200.8348	KLD:0.0857	C_loss:0.0023
Train Epoch: 0 [1920/6000 (32%)]	Loss: 211.629257	BCE:211.5366	KLD:0.0904	C_loss:0.0023
Train Epoch: 0 [2560/6000 (43%)]	Loss: 190.263626	BCE:190.1572	KLD:0.1046	C_loss:0.0018
Train Epoch: 0 [3200/6000 (53%)]	Loss: 179.142502	BCE:179.0295	KLD:0.1113	C_loss:0.0017
Train Epoch: 0 [3840/6000 (64%)]	Loss: 172.432327	BCE:172.3061	KLD:0.1249	C_loss:0.0014
Train Epoch: 0 [4480/6000 (74%)]	Loss: 192.178711	BCE:192.0602	KLD:0.1167	C_loss:0.0018
Train Epoch: 0 [5120/6000 (85%)]	Loss: 189.868103	BCE:189.7449	KLD:0.1214	C_loss:0.0018
Train Epoch: 0 [5760/6000 (96%)]	Loss: 183.403625	BCE:183.2590	KLD:0.1437	C_loss:0.0010
====> Epoch: 0 Average loss: 190.8262	Classifier Accuracy: 75.8256
====> Test set loss: 183.7011
Train Epoch: 0 [0/6000 (0%)]	Loss: 185.901398	BCE:185.8089	KLD:0.0903	C_loss:0.0022
Train Epoch: 0 [640/6000 (11%)]	Loss: 180.612854	BCE:180.5113	KLD:0.0998	C_loss:0.0017
Train Epoch: 0 [1280/6000 (21%)]	Loss: 187.739365	BCE:187.6005	KLD:0.1373	C_loss:0.0015
Train Epoch: 0 [1920/6000 (32%)]	Loss: 176.742996	BCE:176.6257	KLD:0.1157	C_loss:0.0016
Train Epoch: 0 [2560/6000 (43%)]	Loss: 172.533752	BCE:172.4219	KLD:0.1106	C_loss:0.0013
Train Epoch: 0 [3200/6000 (53%)]	Loss: 178.674118	BCE:178.5573	KLD:0.1154	C_loss:0.0014
Train Epoch: 0 [3840/6000 (64%)]	Loss: 187.303452	BCE:187.1540	KLD:0.1481	C_loss:0.0014
Train Epoch: 0 [4480/6000 (74%)]	Loss: 174.389114	BCE:174.2505	KLD:0.1376	C_loss:0.0010
Train Epoch: 0 [5120/6000 (85%)]	Loss: 171.471680	BCE:171.2470	KLD:0.2238	C_loss:0.0009
Train Epoch: 0 [5760/6000 (96%)]	Loss: 170.861145	BCE:170.3833	KLD:0.4767	C_loss:0.0012
====> Epoch: 0 Average loss: 181.2567	Classifier Accuracy: 82.3194
====> Test set loss: 180.6757
Train Epoch: 0 [0/6000 (0%)]	Loss: 183.913452	BCE:183.4539	KLD:0.4576	C_loss:0.0019
Train Epoch: 0 [640/6000 (11%)]	Loss: 172.676071	BCE:171.8013	KLD:0.8731	C_loss:0.0017
Train Epoch: 0 [1280/6000 (21%)]	Loss: 175.429947	BCE:174.2188	KLD:1.2097	C_loss:0.0014
Train Epoch: 0 [1920/6000 (32%)]	Loss: 184.419662	BCE:180.8132	KLD:3.6049	C_loss:0.0015
Train Epoch: 0 [2560/6000 (43%)]	Loss: 159.858093	BCE:157.2574	KLD:2.5993	C_loss:0.0014
Train Epoch: 0 [3200/6000 (53%)]	Loss: 165.776962	BCE:163.0641	KLD:2.7114	C_loss:0.0015
Train Epoch: 0 [3840/6000 (64%)]	Loss: 167.784546	BCE:164.6553	KLD:3.1279	C_loss:0.0013
Train Epoch: 0 [4480/6000 (74%)]	Loss: 164.043137	BCE:160.2903	KLD:3.7514	C_loss:0.0014
Train Epoch: 0 [5120/6000 (85%)]	Loss: 172.289261	BCE:167.6397	KLD:4.6483	C_loss:0.0012
Train Epoch: 0 [5760/6000 (96%)]	Loss: 165.260666	BCE:159.1377	KLD:6.1215	C_loss:0.0015
====> Epoch: 0 Average loss: 169.7386	Classifier Accuracy: 81.6379
====> Test set loss: 162.2709
Train Epoch: 0 [0/6000 (0%)]	Loss: 158.229767	BCE:152.5840	KLD:5.6439	C_loss:0.0019
Train Epoch: 0 [640/6000 (11%)]	Loss: 153.364700	BCE:147.5688	KLD:5.7948	C_loss:0.0011
Train Epoch: 0 [1280/6000 (21%)]	Loss: 155.922485	BCE:150.7386	KLD:5.1825	C_loss:0.0014
Train Epoch: 0 [1920/6000 (32%)]	Loss: 153.685638	BCE:147.8260	KLD:5.8585	C_loss:0.0011
Train Epoch: 0 [2560/6000 (43%)]	Loss: 137.091141	BCE:130.7086	KLD:6.3816	C_loss:0.0010
Train Epoch: 0 [3200/6000 (53%)]	Loss: 151.588272	BCE:145.3600	KLD:6.2274	C_loss:0.0008
Train Epoch: 0 [3840/6000 (64%)]	Loss: 154.395508	BCE:147.8285	KLD:6.5659	C_loss:0.0011
Train Epoch: 0 [4480/6000 (74%)]	Loss: 146.051758	BCE:140.0745	KLD:5.9761	C_loss:0.0011
Train Epoch: 0 [5120/6000 (85%)]	Loss: 147.686295	BCE:140.8587	KLD:6.8265	C_loss:0.0011
Train Epoch: 0 [5760/6000 (96%)]	Loss: 149.093109	BCE:140.8981	KLD:8.1939	C_loss:0.0012
====> Epoch: 0 Average loss: 153.7391	Classifier Accuracy: 81.1392
====> Test set loss: 154.1773
Train Epoch: 0 [0/6000 (0%)]	Loss: 543.841370	BCE:543.7593	KLD:0.0770	C_loss:0.0051
Train Epoch: 0 [640/6000 (11%)]	Loss: 410.040802	BCE:409.9776	KLD:0.0591	C_loss:0.0041
Train Epoch: 0 [1280/6000 (21%)]	Loss: 378.407806	BCE:378.3516	KLD:0.0528	C_loss:0.0034
Train Epoch: 0 [1920/6000 (32%)]	Loss: 343.065674	BCE:342.9871	KLD:0.0760	C_loss:0.0026
Train Epoch: 0 [2560/6000 (43%)]	Loss: 289.147522	BCE:286.5790	KLD:2.5665	C_loss:0.0021
Train Epoch: 0 [3200/6000 (53%)]	Loss: 254.997726	BCE:252.4266	KLD:2.5694	C_loss:0.0017
Train Epoch: 0 [3840/6000 (64%)]	Loss: 228.749313	BCE:227.2426	KLD:1.5056	C_loss:0.0011
Train Epoch: 0 [4480/6000 (74%)]	Loss: 214.305328	BCE:213.5724	KLD:0.7313	C_loss:0.0016
Train Epoch: 0 [5120/6000 (85%)]	Loss: 201.778122	BCE:201.3414	KLD:0.4352	C_loss:0.0015
Train Epoch: 0 [5760/6000 (96%)]	Loss: 194.568558	BCE:194.2044	KLD:0.3625	C_loss:0.0016
====> Epoch: 0 Average loss: 293.7812	Classifier Accuracy: 76.1026
====> Test set loss: 194.8790
Train Epoch: 0 [0/6000 (0%)]	Loss: 190.119980	BCE:189.8455	KLD:0.2680	C_loss:0.0065
Train Epoch: 0 [640/6000 (11%)]	Loss: 196.796143	BCE:195.5876	KLD:1.2058	C_loss:0.0027
Train Epoch: 0 [1280/6000 (21%)]	Loss: 197.338577	BCE:197.2232	KLD:0.1133	C_loss:0.0021
Train Epoch: 0 [1920/6000 (32%)]	Loss: 201.668259	BCE:201.5676	KLD:0.0988	C_loss:0.0018
Train Epoch: 0 [2560/6000 (43%)]	Loss: 195.500778	BCE:195.4027	KLD:0.0960	C_loss:0.0021
Train Epoch: 0 [3200/6000 (53%)]	Loss: 212.730743	BCE:212.6289	KLD:0.0998	C_loss:0.0021
Train Epoch: 0 [3840/6000 (64%)]	Loss: 192.405060	BCE:192.2971	KLD:0.1061	C_loss:0.0018
Train Epoch: 0 [4480/6000 (74%)]	Loss: 186.445267	BCE:186.3253	KLD:0.1187	C_loss:0.0013
Train Epoch: 0 [5120/6000 (85%)]	Loss: 180.621506	BCE:180.3947	KLD:0.2254	C_loss:0.0014
Train Epoch: 0 [5760/6000 (96%)]	Loss: 184.098190	BCE:183.9848	KLD:0.1122	C_loss:0.0012
====> Epoch: 0 Average loss: 191.3029	Classifier Accuracy: 78.4131
====> Test set loss: 179.3737
Train Epoch: 0 [0/6000 (0%)]	Loss: 176.449875	BCE:176.3113	KLD:0.1375	C_loss:0.0011
Train Epoch: 0 [640/6000 (11%)]	Loss: 194.860931	BCE:194.7526	KLD:0.1069	C_loss:0.0014
Train Epoch: 0 [1280/6000 (21%)]	Loss: 197.029953	BCE:196.9068	KLD:0.1218	C_loss:0.0014
Train Epoch: 0 [1920/6000 (32%)]	Loss: 182.509583	BCE:182.3927	KLD:0.1156	C_loss:0.0013
Train Epoch: 0 [2560/6000 (43%)]	Loss: 182.773163	BCE:182.6608	KLD:0.1115	C_loss:0.0009
Train Epoch: 0 [3200/6000 (53%)]	Loss: 191.526871	BCE:191.4043	KLD:0.1210	C_loss:0.0016
Train Epoch: 0 [3840/6000 (64%)]	Loss: 174.273010	BCE:174.1453	KLD:0.1266	C_loss:0.0010
Train Epoch: 0 [4480/6000 (74%)]	Loss: 170.546860	BCE:170.4125	KLD:0.1333	C_loss:0.0011
Train Epoch: 0 [5120/6000 (85%)]	Loss: 184.631348	BCE:184.5023	KLD:0.1277	C_loss:0.0014
Train Epoch: 0 [5760/6000 (96%)]	Loss: 172.577988	BCE:172.4654	KLD:0.1117	C_loss:0.0008
====> Epoch: 0 Average loss: 182.4991	Classifier Accuracy: 86.0649
====> Test set loss: 175.8609
Train Epoch: 0 [0/6000 (0%)]	Loss: 177.603058	BCE:177.4488	KLD:0.1529	C_loss:0.0013
Train Epoch: 0 [640/6000 (11%)]	Loss: 173.330383	BCE:173.2059	KLD:0.1236	C_loss:0.0009
Train Epoch: 0 [1280/6000 (21%)]	Loss: 190.160049	BCE:190.0350	KLD:0.1235	C_loss:0.0016
Train Epoch: 0 [1920/6000 (32%)]	Loss: 183.388123	BCE:183.2708	KLD:0.1158	C_loss:0.0016
Train Epoch: 0 [2560/6000 (43%)]	Loss: 181.813522	BCE:181.7069	KLD:0.1056	C_loss:0.0010
Train Epoch: 0 [3200/6000 (53%)]	Loss: 177.309433	BCE:177.1975	KLD:0.1110	C_loss:0.0009
Train Epoch: 0 [3840/6000 (64%)]	Loss: 177.464279	BCE:177.3505	KLD:0.1119	C_loss:0.0019
Train Epoch: 0 [4480/6000 (74%)]	Loss: 179.023239	BCE:178.5819	KLD:0.4400	C_loss:0.0013
Train Epoch: 0 [5120/6000 (85%)]	Loss: 179.655975	BCE:177.9096	KLD:1.7454	C_loss:0.0009
Train Epoch: 0 [5760/6000 (96%)]	Loss: 168.170700	BCE:166.8089	KLD:1.3609	C_loss:0.0009
====> Epoch: 0 Average loss: 177.7939	Classifier Accuracy: 86.7797
====> Test set loss: 168.3372
Train Epoch: 0 [0/6000 (0%)]	Loss: 159.246368	BCE:156.6584	KLD:2.5871	C_loss:0.0009
Train Epoch: 0 [640/6000 (11%)]	Loss: 174.399933	BCE:172.4744	KLD:1.9243	C_loss:0.0012
Train Epoch: 0 [1280/6000 (21%)]	Loss: 168.180359	BCE:166.0889	KLD:2.0902	C_loss:0.0012
Train Epoch: 0 [1920/6000 (32%)]	Loss: 174.952118	BCE:171.7755	KLD:3.1759	C_loss:0.0007
Train Epoch: 0 [2560/6000 (43%)]	Loss: 166.482620	BCE:162.8065	KLD:3.6755	C_loss:0.0006
Train Epoch: 0 [3200/6000 (53%)]	Loss: 162.143951	BCE:158.4902	KLD:3.6528	C_loss:0.0009
Train Epoch: 0 [3840/6000 (64%)]	Loss: 150.914963	BCE:144.8352	KLD:6.0785	C_loss:0.0013
Train Epoch: 0 [4480/6000 (74%)]	Loss: 146.921661	BCE:141.0922	KLD:5.8285	C_loss:0.0010
Train Epoch: 0 [5120/6000 (85%)]	Loss: 156.239059	BCE:148.8547	KLD:7.3835	C_loss:0.0009
Train Epoch: 0 [5760/6000 (96%)]	Loss: 157.054535	BCE:151.8925	KLD:5.1608	C_loss:0.0013
====> Epoch: 0 Average loss: 161.3086	Classifier Accuracy: 88.3477
====> Test set loss: 149.9841
Train Epoch: 0 [0/6000 (0%)]	Loss: 543.846558	BCE:543.7645	KLD:0.0770	C_loss:0.0051
Train Epoch: 0 [640/6000 (11%)]	Loss: 422.576782	BCE:422.5117	KLD:0.0608	C_loss:0.0043
Train Epoch: 0 [1280/6000 (21%)]	Loss: 376.305634	BCE:376.2513	KLD:0.0509	C_loss:0.0034
Train Epoch: 0 [1920/6000 (32%)]	Loss: 338.640686	BCE:338.5731	KLD:0.0651	C_loss:0.0024
Train Epoch: 0 [2560/6000 (43%)]	Loss: 279.704681	BCE:276.7246	KLD:2.9780	C_loss:0.0021
Train Epoch: 0 [3200/6000 (53%)]	Loss: 251.132889	BCE:249.4283	KLD:1.7026	C_loss:0.0020
Train Epoch: 0 [3840/6000 (64%)]	Loss: 227.627899	BCE:226.3381	KLD:1.2882	C_loss:0.0015
Train Epoch: 0 [4480/6000 (74%)]	Loss: 208.549789	BCE:207.4387	KLD:1.1093	C_loss:0.0018
Train Epoch: 0 [5120/6000 (85%)]	Loss: 199.268219	BCE:198.4266	KLD:0.8404	C_loss:0.0013
Train Epoch: 0 [5760/6000 (96%)]	Loss: 186.921143	BCE:186.3638	KLD:0.5562	C_loss:0.0012
====> Epoch: 0 Average loss: 294.0556	Classifier Accuracy: 76.5957
====> Test set loss: 195.5771
Train Epoch: 0 [0/6000 (0%)]	Loss: 204.127090	BCE:203.7015	KLD:0.4170	C_loss:0.0086
Train Epoch: 0 [640/6000 (11%)]	Loss: 201.002350	BCE:200.3193	KLD:0.6804	C_loss:0.0027
Train Epoch: 0 [1280/6000 (21%)]	Loss: 196.373535	BCE:195.9788	KLD:0.3928	C_loss:0.0019
Train Epoch: 0 [1920/6000 (32%)]	Loss: 184.565750	BCE:184.3143	KLD:0.2497	C_loss:0.0017
Train Epoch: 0 [2560/6000 (43%)]	Loss: 186.572906	BCE:186.2210	KLD:0.3502	C_loss:0.0017
Train Epoch: 0 [3200/6000 (53%)]	Loss: 183.760254	BCE:183.5404	KLD:0.2181	C_loss:0.0017
Train Epoch: 0 [3840/6000 (64%)]	Loss: 180.495712	BCE:180.2895	KLD:0.2050	C_loss:0.0012
Train Epoch: 0 [4480/6000 (74%)]	Loss: 188.229050	BCE:187.9332	KLD:0.2944	C_loss:0.0015
Train Epoch: 0 [5120/6000 (85%)]	Loss: 180.176559	BCE:179.9585	KLD:0.2166	C_loss:0.0014
Train Epoch: 0 [5760/6000 (96%)]	Loss: 169.009369	BCE:168.8642	KLD:0.1437	C_loss:0.0015
====> Epoch: 0 Average loss: 188.0426	Classifier Accuracy: 79.0171
====> Test set loss: 179.1145
Train Epoch: 0 [0/6000 (0%)]	Loss: 183.394012	BCE:183.2005	KLD:0.1920	C_loss:0.0015
Train Epoch: 0 [640/6000 (11%)]	Loss: 180.608704	BCE:180.4731	KLD:0.1343	C_loss:0.0013
Train Epoch: 0 [1280/6000 (21%)]	Loss: 187.648331	BCE:187.5161	KLD:0.1308	C_loss:0.0015
Train Epoch: 0 [1920/6000 (32%)]	Loss: 185.346191	BCE:185.1153	KLD:0.2298	C_loss:0.0011
Train Epoch: 0 [2560/6000 (43%)]	Loss: 175.470917	BCE:175.2890	KLD:0.1803	C_loss:0.0016
Train Epoch: 0 [3200/6000 (53%)]	Loss: 182.332260	BCE:182.1499	KLD:0.1809	C_loss:0.0015
Train Epoch: 0 [3840/6000 (64%)]	Loss: 171.470947	BCE:171.3497	KLD:0.1201	C_loss:0.0012
Train Epoch: 0 [4480/6000 (74%)]	Loss: 192.040833	BCE:191.8149	KLD:0.2247	C_loss:0.0013
Train Epoch: 0 [5120/6000 (85%)]	Loss: 173.789627	BCE:173.5837	KLD:0.2049	C_loss:0.0010
Train Epoch: 0 [5760/6000 (96%)]	Loss: 177.770279	BCE:177.4204	KLD:0.3492	C_loss:0.0007
====> Epoch: 0 Average loss: 180.9720	Classifier Accuracy: 85.7602
====> Test set loss: 177.1713
Train Epoch: 0 [0/6000 (0%)]	Loss: 174.285492	BCE:173.2881	KLD:0.9962	C_loss:0.0011
Train Epoch: 0 [640/6000 (11%)]	Loss: 182.939606	BCE:182.7178	KLD:0.2205	C_loss:0.0013
Train Epoch: 0 [1280/6000 (21%)]	Loss: 182.161179	BCE:181.2636	KLD:0.8958	C_loss:0.0017
Train Epoch: 0 [1920/6000 (32%)]	Loss: 174.737183	BCE:172.5792	KLD:2.1565	C_loss:0.0015
Train Epoch: 0 [2560/6000 (43%)]	Loss: 171.306732	BCE:168.7238	KLD:2.5816	C_loss:0.0013
Train Epoch: 0 [3200/6000 (53%)]	Loss: 164.490509	BCE:159.3401	KLD:5.1492	C_loss:0.0012
Train Epoch: 0 [3840/6000 (64%)]	Loss: 168.495514	BCE:163.1445	KLD:5.3500	C_loss:0.0011
Train Epoch: 0 [4480/6000 (74%)]	Loss: 150.920959	BCE:146.0532	KLD:4.8667	C_loss:0.0010
Train Epoch: 0 [5120/6000 (85%)]	Loss: 168.732285	BCE:160.9786	KLD:7.7527	C_loss:0.0010
Train Epoch: 0 [5760/6000 (96%)]	Loss: 163.033051	BCE:156.4096	KLD:6.6225	C_loss:0.0009
====> Epoch: 0 Average loss: 169.3130	Classifier Accuracy: 86.4916
====> Test set loss: 157.5400
Train Epoch: 0 [0/6000 (0%)]	Loss: 160.923172	BCE:155.7075	KLD:5.2146	C_loss:0.0011
Train Epoch: 0 [640/6000 (11%)]	Loss: 160.190506	BCE:155.2212	KLD:4.9682	C_loss:0.0012
Train Epoch: 0 [1280/6000 (21%)]	Loss: 145.102844	BCE:140.5730	KLD:4.5290	C_loss:0.0008
Train Epoch: 0 [1920/6000 (32%)]	Loss: 158.171295	BCE:151.2531	KLD:6.9170	C_loss:0.0012
Train Epoch: 0 [2560/6000 (43%)]	Loss: 142.957870	BCE:137.5400	KLD:5.4171	C_loss:0.0008
Train Epoch: 0 [3200/6000 (53%)]	Loss: 143.131500	BCE:136.6685	KLD:6.4620	C_loss:0.0011
Train Epoch: 0 [3840/6000 (64%)]	Loss: 145.285797	BCE:139.3600	KLD:5.9247	C_loss:0.0011
Train Epoch: 0 [4480/6000 (74%)]	Loss: 151.446640	BCE:143.6103	KLD:7.8354	C_loss:0.0009
Train Epoch: 0 [5120/6000 (85%)]	Loss: 148.889053	BCE:142.3063	KLD:6.5817	C_loss:0.0010
Train Epoch: 0 [5760/6000 (96%)]	Loss: 139.985825	BCE:131.3748	KLD:8.6103	C_loss:0.0008
====> Epoch: 0 Average loss: 153.3948	Classifier Accuracy: 88.4142
====> Test set loss: 146.1596
Train Epoch: 0 [0/6000 (0%)]	Loss: 543.830505	BCE:543.7485	KLD:0.0770	C_loss:0.0051
Train Epoch: 0 [640/6000 (11%)]	Loss: 414.589478	BCE:414.5234	KLD:0.0619	C_loss:0.0041
Train Epoch: 0 [1280/6000 (21%)]	Loss: 382.963531	BCE:382.8990	KLD:0.0612	C_loss:0.0033
Train Epoch: 0 [1920/6000 (32%)]	Loss: 356.082703	BCE:356.0126	KLD:0.0675	C_loss:0.0026
Train Epoch: 0 [2560/6000 (43%)]	Loss: 288.303955	BCE:288.2193	KLD:0.0828	C_loss:0.0019
Train Epoch: 0 [3200/6000 (53%)]	Loss: 237.396301	BCE:237.2781	KLD:0.1166	C_loss:0.0016
Train Epoch: 0 [3840/6000 (64%)]	Loss: 225.328064	BCE:224.8649	KLD:0.4617	C_loss:0.0015
Train Epoch: 0 [4480/6000 (74%)]	Loss: 202.827515	BCE:202.5703	KLD:0.2563	C_loss:0.0009
Train Epoch: 0 [5120/6000 (85%)]	Loss: 207.922653	BCE:207.5796	KLD:0.3419	C_loss:0.0012
Train Epoch: 0 [5760/6000 (96%)]	Loss: 207.196823	BCE:207.0371	KLD:0.1588	C_loss:0.0009
====> Epoch: 0 Average loss: 296.8905	Classifier Accuracy: 78.2247
====> Test set loss: 194.6515
Train Epoch: 0 [0/6000 (0%)]	Loss: 191.944351	BCE:191.6760	KLD:0.2601	C_loss:0.0082
Train Epoch: 0 [640/6000 (11%)]	Loss: 197.168259	BCE:197.0015	KLD:0.1643	C_loss:0.0025
Train Epoch: 0 [1280/6000 (21%)]	Loss: 196.330902	BCE:196.2295	KLD:0.0995	C_loss:0.0019
Train Epoch: 0 [1920/6000 (32%)]	Loss: 186.005295	BCE:185.9128	KLD:0.0905	C_loss:0.0020
Train Epoch: 0 [2560/6000 (43%)]	Loss: 183.915375	BCE:183.7087	KLD:0.2052	C_loss:0.0014
Train Epoch: 0 [3200/6000 (53%)]	Loss: 191.884827	BCE:191.7142	KLD:0.1683	C_loss:0.0023
Train Epoch: 0 [3840/6000 (64%)]	Loss: 173.565872	BCE:173.4447	KLD:0.1198	C_loss:0.0014
Train Epoch: 0 [4480/6000 (74%)]	Loss: 186.659073	BCE:186.5184	KLD:0.1395	C_loss:0.0012
Train Epoch: 0 [5120/6000 (85%)]	Loss: 192.828537	BCE:192.6896	KLD:0.1376	C_loss:0.0014
Train Epoch: 0 [5760/6000 (96%)]	Loss: 188.659424	BCE:188.5634	KLD:0.0948	C_loss:0.0012
====> Epoch: 0 Average loss: 190.5077	Classifier Accuracy: 78.7179
====> Test set loss: 181.3860
Train Epoch: 0 [0/6000 (0%)]	Loss: 177.996872	BCE:177.8804	KLD:0.1153	C_loss:0.0011
Train Epoch: 0 [640/6000 (11%)]	Loss: 204.200500	BCE:204.1064	KLD:0.0929	C_loss:0.0012
Train Epoch: 0 [1280/6000 (21%)]	Loss: 187.011597	BCE:186.8929	KLD:0.1171	C_loss:0.0016
Train Epoch: 0 [1920/6000 (32%)]	Loss: 181.562241	BCE:181.4592	KLD:0.1021	C_loss:0.0009
Train Epoch: 0 [2560/6000 (43%)]	Loss: 189.699829	BCE:189.5725	KLD:0.1260	C_loss:0.0013
Train Epoch: 0 [3200/6000 (53%)]	Loss: 182.280029	BCE:182.1670	KLD:0.1116	C_loss:0.0014
Train Epoch: 0 [3840/6000 (64%)]	Loss: 182.356659	BCE:182.2485	KLD:0.1068	C_loss:0.0013
Train Epoch: 0 [4480/6000 (74%)]	Loss: 177.219818	BCE:177.0796	KLD:0.1394	C_loss:0.0009
Train Epoch: 0 [5120/6000 (85%)]	Loss: 186.097687	BCE:185.9752	KLD:0.1212	C_loss:0.0013
Train Epoch: 0 [5760/6000 (96%)]	Loss: 176.043671	BCE:175.9352	KLD:0.1077	C_loss:0.0007
====> Epoch: 0 Average loss: 182.4276	Classifier Accuracy: 86.9348
====> Test set loss: 177.8142
Train Epoch: 0 [0/6000 (0%)]	Loss: 172.872742	BCE:172.7163	KLD:0.1555	C_loss:0.0010
Train Epoch: 0 [640/6000 (11%)]	Loss: 182.210907	BCE:182.1195	KLD:0.0900	C_loss:0.0014
Train Epoch: 0 [1280/6000 (21%)]	Loss: 187.508331	BCE:187.3923	KLD:0.1149	C_loss:0.0011
Train Epoch: 0 [1920/6000 (32%)]	Loss: 183.975342	BCE:183.8047	KLD:0.1694	C_loss:0.0012
Train Epoch: 0 [2560/6000 (43%)]	Loss: 175.685150	BCE:175.5076	KLD:0.1766	C_loss:0.0009
Train Epoch: 0 [3200/6000 (53%)]	Loss: 174.607315	BCE:174.2792	KLD:0.3272	C_loss:0.0010
Train Epoch: 0 [3840/6000 (64%)]	Loss: 178.251602	BCE:177.5998	KLD:0.6508	C_loss:0.0009
Train Epoch: 0 [4480/6000 (74%)]	Loss: 177.969391	BCE:175.7070	KLD:2.2610	C_loss:0.0013
Train Epoch: 0 [5120/6000 (85%)]	Loss: 173.634537	BCE:171.4073	KLD:2.2262	C_loss:0.0010
Train Epoch: 0 [5760/6000 (96%)]	Loss: 162.774338	BCE:158.4193	KLD:4.3540	C_loss:0.0010
====> Epoch: 0 Average loss: 176.0962	Classifier Accuracy: 88.3976
====> Test set loss: 162.5018
Train Epoch: 0 [0/6000 (0%)]	Loss: 162.898926	BCE:159.5567	KLD:3.3414	C_loss:0.0008
Train Epoch: 0 [640/6000 (11%)]	Loss: 171.617569	BCE:166.8449	KLD:4.7720	C_loss:0.0006
Train Epoch: 0 [1280/6000 (21%)]	Loss: 156.711304	BCE:152.0848	KLD:4.6251	C_loss:0.0013
Train Epoch: 0 [1920/6000 (32%)]	Loss: 154.929962	BCE:151.5006	KLD:3.4286	C_loss:0.0008
Train Epoch: 0 [2560/6000 (43%)]	Loss: 155.114258	BCE:149.9938	KLD:5.1192	C_loss:0.0012
Train Epoch: 0 [3200/6000 (53%)]	Loss: 151.968201	BCE:146.8017	KLD:5.1656	C_loss:0.0009
Train Epoch: 0 [3840/6000 (64%)]	Loss: 158.813950	BCE:152.0362	KLD:6.7766	C_loss:0.0011
Train Epoch: 0 [4480/6000 (74%)]	Loss: 143.524078	BCE:138.1960	KLD:5.3274	C_loss:0.0007
Train Epoch: 0 [5120/6000 (85%)]	Loss: 150.701447	BCE:142.9360	KLD:7.7640	C_loss:0.0014
Train Epoch: 0 [5760/6000 (96%)]	Loss: 148.352463	BCE:141.1946	KLD:7.1567	C_loss:0.0012
====> Epoch: 0 Average loss: 157.6747	Classifier Accuracy: 88.5084
====> Test set loss: 149.5705
Train Epoch: 0 [0/6000 (0%)]	Loss: 543.845276	BCE:543.7632	KLD:0.0770	C_loss:0.0051
Train Epoch: 0 [640/6000 (11%)]	Loss: 419.219849	BCE:419.1556	KLD:0.0601	C_loss:0.0042
Train Epoch: 0 [1280/6000 (21%)]	Loss: 376.818085	BCE:376.7506	KLD:0.0643	C_loss:0.0032
Train Epoch: 0 [1920/6000 (32%)]	Loss: 349.457153	BCE:349.3295	KLD:0.1252	C_loss:0.0024
Train Epoch: 0 [2560/6000 (43%)]	Loss: 278.244385	BCE:272.6808	KLD:5.5613	C_loss:0.0022
Train Epoch: 0 [3200/6000 (53%)]	Loss: 244.643753	BCE:243.2896	KLD:1.3519	C_loss:0.0023
Train Epoch: 0 [3840/6000 (64%)]	Loss: 221.114151	BCE:219.0621	KLD:2.0506	C_loss:0.0015
Train Epoch: 0 [4480/6000 (74%)]	Loss: 214.652649	BCE:213.3431	KLD:1.3081	C_loss:0.0014
Train Epoch: 0 [5120/6000 (85%)]	Loss: 207.674225	BCE:206.9072	KLD:0.7656	C_loss:0.0014
Train Epoch: 0 [5760/6000 (96%)]	Loss: 208.883255	BCE:208.3411	KLD:0.5409	C_loss:0.0012
====> Epoch: 0 Average loss: 293.8264	Classifier Accuracy: 76.8395
====> Test set loss: 199.5999
Train Epoch: 0 [0/6000 (0%)]	Loss: 198.039017	BCE:197.6472	KLD:0.3834	C_loss:0.0084
Train Epoch: 0 [640/6000 (11%)]	Loss: 204.093369	BCE:203.4717	KLD:0.6191	C_loss:0.0026
Train Epoch: 0 [1280/6000 (21%)]	Loss: 193.436615	BCE:193.3207	KLD:0.1138	C_loss:0.0021
Train Epoch: 0 [1920/6000 (32%)]	Loss: 191.467361	BCE:191.3512	KLD:0.1139	C_loss:0.0023
Train Epoch: 0 [2560/6000 (43%)]	Loss: 188.893188	BCE:188.7585	KLD:0.1330	C_loss:0.0016
Train Epoch: 0 [3200/6000 (53%)]	Loss: 189.465744	BCE:189.3114	KLD:0.1528	C_loss:0.0015
Train Epoch: 0 [3840/6000 (64%)]	Loss: 187.315338	BCE:187.1819	KLD:0.1320	C_loss:0.0015
Train Epoch: 0 [4480/6000 (74%)]	Loss: 181.927261	BCE:181.7599	KLD:0.1656	C_loss:0.0017
Train Epoch: 0 [5120/6000 (85%)]	Loss: 179.566742	BCE:179.3941	KLD:0.1715	C_loss:0.0012
Train Epoch: 0 [5760/6000 (96%)]	Loss: 190.959015	BCE:190.7966	KLD:0.1610	C_loss:0.0014
====> Epoch: 0 Average loss: 191.1805	Classifier Accuracy: 78.3023
====> Test set loss: 182.0877
Train Epoch: 0 [0/6000 (0%)]	Loss: 184.678879	BCE:184.4940	KLD:0.1837	C_loss:0.0012
Train Epoch: 0 [640/6000 (11%)]	Loss: 202.749847	BCE:202.5694	KLD:0.1787	C_loss:0.0018
Train Epoch: 0 [1280/6000 (21%)]	Loss: 184.598465	BCE:184.4094	KLD:0.1878	C_loss:0.0013
Train Epoch: 0 [1920/6000 (32%)]	Loss: 181.890366	BCE:181.7263	KLD:0.1631	C_loss:0.0010
Train Epoch: 0 [2560/6000 (43%)]	Loss: 178.511322	BCE:178.3448	KLD:0.1654	C_loss:0.0011
Train Epoch: 0 [3200/6000 (53%)]	Loss: 181.633514	BCE:181.4971	KLD:0.1353	C_loss:0.0011
Train Epoch: 0 [3840/6000 (64%)]	Loss: 183.191223	BCE:183.0669	KLD:0.1233	C_loss:0.0010
Train Epoch: 0 [4480/6000 (74%)]	Loss: 179.885254	BCE:179.7279	KLD:0.1558	C_loss:0.0016
Train Epoch: 0 [5120/6000 (85%)]	Loss: 168.569855	BCE:168.2844	KLD:0.2843	C_loss:0.0011
Train Epoch: 0 [5760/6000 (96%)]	Loss: 180.314880	BCE:179.8556	KLD:0.4580	C_loss:0.0013
====> Epoch: 0 Average loss: 182.4459	Classifier Accuracy: 85.9874
====> Test set loss: 175.8775
Train Epoch: 0 [0/6000 (0%)]	Loss: 173.842392	BCE:172.5212	KLD:1.3203	C_loss:0.0009
Train Epoch: 0 [640/6000 (11%)]	Loss: 174.273865	BCE:172.4646	KLD:1.8083	C_loss:0.0010
Train Epoch: 0 [1280/6000 (21%)]	Loss: 175.364426	BCE:173.7180	KLD:1.6449	C_loss:0.0015
Train Epoch: 0 [1920/6000 (32%)]	Loss: 159.967926	BCE:156.3108	KLD:3.6560	C_loss:0.0011
Train Epoch: 0 [2560/6000 (43%)]	Loss: 162.077774	BCE:158.5061	KLD:3.5707	C_loss:0.0010
Train Epoch: 0 [3200/6000 (53%)]	Loss: 167.039429	BCE:162.7632	KLD:4.2746	C_loss:0.0017
Train Epoch: 0 [3840/6000 (64%)]	Loss: 150.006165	BCE:144.6543	KLD:5.3512	C_loss:0.0006
Train Epoch: 0 [4480/6000 (74%)]	Loss: 160.247681	BCE:155.1952	KLD:5.0514	C_loss:0.0011
Train Epoch: 0 [5120/6000 (85%)]	Loss: 161.214828	BCE:155.3099	KLD:5.9042	C_loss:0.0008
Train Epoch: 0 [5760/6000 (96%)]	Loss: 158.094238	BCE:152.4659	KLD:5.6270	C_loss:0.0014
====> Epoch: 0 Average loss: 164.2903	Classifier Accuracy: 87.3504
====> Test set loss: 154.4307
Train Epoch: 0 [0/6000 (0%)]	Loss: 152.809326	BCE:147.2217	KLD:5.5869	C_loss:0.0007
Train Epoch: 0 [640/6000 (11%)]	Loss: 160.919708	BCE:155.6730	KLD:5.2460	C_loss:0.0007
Train Epoch: 0 [1280/6000 (21%)]	Loss: 150.817963	BCE:144.0327	KLD:6.7847	C_loss:0.0005
Train Epoch: 0 [1920/6000 (32%)]	Loss: 153.768127	BCE:147.0046	KLD:6.7625	C_loss:0.0011
Train Epoch: 0 [2560/6000 (43%)]	Loss: 156.016235	BCE:149.3184	KLD:6.6971	C_loss:0.0007
Train Epoch: 0 [3200/6000 (53%)]	Loss: 146.191528	BCE:139.3096	KLD:6.8808	C_loss:0.0012
Train Epoch: 0 [3840/6000 (64%)]	Loss: 142.562180	BCE:134.7283	KLD:7.8327	C_loss:0.0012
Train Epoch: 0 [4480/6000 (74%)]	Loss: 140.122940	BCE:134.2036	KLD:5.9185	C_loss:0.0009
Train Epoch: 0 [5120/6000 (85%)]	Loss: 145.241333	BCE:137.3028	KLD:7.9373	C_loss:0.0013
Train Epoch: 0 [5760/6000 (96%)]	Loss: 148.653137	BCE:140.8814	KLD:7.7704	C_loss:0.0013
====> Epoch: 0 Average loss: 151.0324	Classifier Accuracy: 88.2480
====> Test set loss: 145.6875
Train Epoch: 0 [0/6000 (0%)]	Loss: 543.840454	BCE:543.7584	KLD:0.0770	C_loss:0.0051
Train Epoch: 0 [640/6000 (11%)]	Loss: 416.667084	BCE:416.6003	KLD:0.0627	C_loss:0.0041
Train Epoch: 0 [1280/6000 (21%)]	Loss: 376.050903	BCE:375.9859	KLD:0.0616	C_loss:0.0034
Train Epoch: 0 [1920/6000 (32%)]	Loss: 351.874603	BCE:351.8052	KLD:0.0670	C_loss:0.0024
Train Epoch: 0 [2560/6000 (43%)]	Loss: 302.327789	BCE:301.2422	KLD:1.0836	C_loss:0.0020
Train Epoch: 0 [3200/6000 (53%)]	Loss: 247.845001	BCE:245.1327	KLD:2.7101	C_loss:0.0022
Train Epoch: 0 [3840/6000 (64%)]	Loss: 219.983337	BCE:217.8153	KLD:2.1668	C_loss:0.0012
Train Epoch: 0 [4480/6000 (74%)]	Loss: 207.599747	BCE:206.7127	KLD:0.8856	C_loss:0.0015
Train Epoch: 0 [5120/6000 (85%)]	Loss: 212.365250	BCE:211.7343	KLD:0.6299	C_loss:0.0011
Train Epoch: 0 [5760/6000 (96%)]	Loss: 199.503387	BCE:199.0073	KLD:0.4951	C_loss:0.0010
====> Epoch: 0 Average loss: 299.2219	Classifier Accuracy: 76.8008
OrderedDict([('1.weight', tensor([[ 0.0003, -0.0192,  0.0294,  ..., -0.0219, -0.0037, -0.0021],
        [ 0.0198,  0.0150,  0.0104,  ...,  0.0203,  0.0060,  0.0299],
        [ 0.0201, -0.0149,  0.0333,  ...,  0.0203, -0.0012, -0.0080],
        ...,
        [-0.0018,  0.0295, -0.0085,  ...,  0.0037, -0.0036, -0.0300],
        [ 0.0233,  0.0220,  0.0064,  ..., -0.0115,  0.0324,  0.0158],
        [-0.0309, -0.0066, -0.0125,  ..., -0.0286, -0.0350,  0.0105]],
       device='cuda:0')), ('1.bias', tensor([ 0.0075, -0.0111, -0.0374, -0.0010, -0.0402, -0.0471, -0.0653, -0.0533,
        -0.0193, -0.0415, -0.0110, -0.0546,  0.0107, -0.0404, -0.0138,  0.0167,
         0.0184, -0.0289,  0.0126, -0.0308, -0.0444, -0.0202, -0.0128, -0.0353,
        -0.0226, -0.0008, -0.0366, -0.0129, -0.0513, -0.0193, -0.0070, -0.0439,
        -0.0333,  0.0163, -0.0143, -0.0631, -0.0123, -0.0197,  0.0023,  0.0071,
         0.0204, -0.0152, -0.0220, -0.0182, -0.0129, -0.0424, -0.0268,  0.0316,
         0.0017, -0.0428, -0.0238, -0.0324,  0.0139, -0.0274, -0.0119, -0.0499,
         0.0052, -0.0137, -0.0058, -0.0175, -0.0602,  0.0130,  0.0397, -0.0705,
         0.0477, -0.0198, -0.0364, -0.0019, -0.0344,  0.0029, -0.0451,  0.0177,
        -0.0278, -0.0348, -0.0103, -0.0270, -0.0504, -0.0314, -0.0304, -0.0324,
        -0.0181,  0.0325, -0.0333, -0.0466, -0.0554,  0.0341,  0.0157, -0.0263,
        -0.0625, -0.0371, -0.0056, -0.0096, -0.0130, -0.0181, -0.0111,  0.0181,
        -0.0004, -0.0283,  0.0061, -0.0214, -0.0255, -0.0664, -0.0052, -0.0596,
         0.0025,  0.0118, -0.0070,  0.0145, -0.0339, -0.0388, -0.0004, -0.0434,
        -0.0266, -0.0555, -0.0319, -0.0691,  0.0058,  0.0113, -0.0719, -0.0322,
        -0.0132,  0.0279, -0.0204, -0.0680,  0.0033, -0.0095, -0.0336, -0.0582],
       device='cuda:0')), ('3.weight', tensor([[ 0.1410,  0.0866, -0.0030,  ...,  0.1340,  0.0488,  0.1290],
        [-0.0859, -0.0678, -0.1308,  ...,  0.0834, -0.1008, -0.1055],
        [ 0.0070,  0.0045,  0.0445,  ..., -0.1055, -0.0287,  0.0701],
        ...,
        [ 0.0404,  0.0406,  0.0639,  ...,  0.0096, -0.0425, -0.1133],
        [-0.1270, -0.0806,  0.0843,  ..., -0.1203, -0.0565, -0.1050],
        [ 0.0631, -0.0410, -0.0471,  ..., -0.0249, -0.0010,  0.0483]],
       device='cuda:0')), ('3.bias', tensor([ 0.1031, -0.0675,  0.0192,  0.0406, -0.0569,  0.0465,  0.0268, -0.0551,
         0.0285,  0.0460], device='cuda:0'))])
====> Test set loss: 198.3108
Train Epoch: 0 [0/6000 (0%)]	Loss: 198.357391	BCE:197.8768	KLD:0.4708	C_loss:0.0098
Train Epoch: 0 [640/6000 (11%)]	Loss: 195.051758	BCE:194.5116	KLD:0.5367	C_loss:0.0034
Train Epoch: 0 [1280/6000 (21%)]	Loss: 189.056137	BCE:188.6061	KLD:0.4481	C_loss:0.0019
Train Epoch: 0 [1920/6000 (32%)]	Loss: 186.560425	BCE:186.0292	KLD:0.5291	C_loss:0.0022
Train Epoch: 0 [2560/6000 (43%)]	Loss: 186.665558	BCE:186.4017	KLD:0.2623	C_loss:0.0015
Train Epoch: 0 [3200/6000 (53%)]	Loss: 184.235153	BCE:184.0150	KLD:0.2184	C_loss:0.0018
Train Epoch: 0 [3840/6000 (64%)]	Loss: 188.917221	BCE:188.5445	KLD:0.3715	C_loss:0.0013
Train Epoch: 0 [4480/6000 (74%)]	Loss: 176.135986	BCE:175.9180	KLD:0.2166	C_loss:0.0014
Train Epoch: 0 [5120/6000 (85%)]	Loss: 193.579193	BCE:193.2119	KLD:0.3662	C_loss:0.0011
Train Epoch: 0 [5760/6000 (96%)]	Loss: 175.125458	BCE:174.8773	KLD:0.2467	C_loss:0.0015
====> Epoch: 0 Average loss: 186.9305	Classifier Accuracy: 77.7981
OrderedDict([('1.weight', tensor([[-0.0998, -0.1134, -0.0794,  ..., -0.1154, -0.1026, -0.1014],
        [-0.0862, -0.0895, -0.0927,  ..., -0.0858, -0.0958, -0.0790],
        [-0.0859, -0.1104, -0.0767,  ..., -0.0858, -0.1008, -0.1056],
        ...,
        [-0.1012, -0.0793, -0.1059,  ..., -0.0974, -0.1025, -0.1210],
        [-0.0837, -0.0846, -0.0955,  ..., -0.1081, -0.0773, -0.0890],
        [-0.1217, -0.1046, -0.1088,  ..., -0.1200, -0.1245, -0.0926]],
       device='cuda:0')), ('1.bias', tensor([-0.0980, -0.1069, -0.1321, -0.0985, -0.1186, -0.1384, -0.1467, -0.1398,
        -0.1046, -0.1268, -0.1023, -0.1390, -0.0751, -0.1329, -0.0974, -0.0762,
        -0.0781, -0.1344, -0.0916, -0.1230, -0.1420, -0.1152, -0.1006, -0.1203,
        -0.1007, -0.1044, -0.1190, -0.1113, -0.1237, -0.1151, -0.0966, -0.1298,
        -0.1083, -0.0578, -0.1016, -0.1448, -0.1119, -0.1149, -0.0935, -0.0801,
        -0.0822, -0.1021, -0.0970, -0.1154, -0.1100, -0.1287, -0.1228, -0.0905,
        -0.0832, -0.1098, -0.1053, -0.1255, -0.0920, -0.1028, -0.1080, -0.1380,
        -0.0831, -0.1181, -0.0939, -0.1073, -0.1312, -0.0691, -0.0880, -0.1653,
        -0.0497, -0.1019, -0.1235, -0.0979, -0.1212, -0.0945, -0.1317, -0.0718,
        -0.1080, -0.1231, -0.0964, -0.1151, -0.1371, -0.1242, -0.1271, -0.1198,
        -0.1001, -0.0622, -0.1193, -0.1300, -0.1332, -0.0793, -0.1116, -0.1162,
        -0.1407, -0.1334, -0.0902, -0.0889, -0.1014, -0.1078, -0.1004, -0.0823,
        -0.0826, -0.1068, -0.0962, -0.0909, -0.1125, -0.1595, -0.0900, -0.1546,
        -0.0874, -0.0822, -0.0919, -0.0818, -0.1152, -0.1153, -0.0987, -0.1358,
        -0.1295, -0.1337, -0.1154, -0.1674, -0.0991, -0.0778, -0.1588, -0.1231,
        -0.1270, -0.0694, -0.1290, -0.1475, -0.0690, -0.0936, -0.1170, -0.1503],
       device='cuda:0')), ('3.weight', tensor([[-0.0055, -0.0451, -0.1123,  ..., -0.0121, -0.0713, -0.0147],
        [-0.1607, -0.1637, -0.1917,  ..., -0.0536, -0.1732, -0.1754],
        [-0.0943, -0.0933, -0.0692,  ..., -0.1710, -0.1084, -0.0442],
        ...,
        [-0.0761, -0.0750, -0.0530,  ..., -0.0922, -0.1266, -0.1880],
        [-0.1864, -0.1513, -0.0497,  ..., -0.1805, -0.1462, -0.1687],
        [-0.0520, -0.1255, -0.1378,  ..., -0.1127, -0.0948, -0.0660]],
       device='cuda:0')), ('3.bias', tensor([-0.0284, -0.1654, -0.0796, -0.0657, -0.1476, -0.0695, -0.0861, -0.1496,
        -0.0741, -0.0650], device='cuda:0'))])
====> Test set loss: 181.0709
Train Epoch: 0 [0/6000 (0%)]	Loss: 178.272766	BCE:178.0750	KLD:0.1967	C_loss:0.0010
Train Epoch: 0 [640/6000 (11%)]	Loss: 191.888794	BCE:191.7341	KLD:0.1533	C_loss:0.0014
Train Epoch: 0 [1280/6000 (21%)]	Loss: 175.668472	BCE:175.4973	KLD:0.1694	C_loss:0.0018
Train Epoch: 0 [1920/6000 (32%)]	Loss: 172.965591	BCE:172.7552	KLD:0.2089	C_loss:0.0015
Train Epoch: 0 [2560/6000 (43%)]	Loss: 181.560913	BCE:181.3872	KLD:0.1723	C_loss:0.0014
Train Epoch: 0 [3200/6000 (53%)]	Loss: 169.264755	BCE:169.1226	KLD:0.1408	C_loss:0.0013
Train Epoch: 0 [3840/6000 (64%)]	Loss: 180.591354	BCE:180.4280	KLD:0.1620	C_loss:0.0013
Train Epoch: 0 [4480/6000 (74%)]	Loss: 181.711716	BCE:181.5446	KLD:0.1662	C_loss:0.0009
Train Epoch: 0 [5120/6000 (85%)]	Loss: 185.554367	BCE:185.3723	KLD:0.1809	C_loss:0.0012
Train Epoch: 0 [5760/6000 (96%)]	Loss: 178.328781	BCE:178.1462	KLD:0.1819	C_loss:0.0007
====> Epoch: 0 Average loss: 181.4498	Classifier Accuracy: 85.5829
OrderedDict([('1.weight', tensor([[-0.0998, -0.1134, -0.0794,  ..., -0.1154, -0.1026, -0.1014],
        [-0.0862, -0.0895, -0.0927,  ..., -0.0858, -0.0958, -0.0790],
        [-0.0859, -0.1104, -0.0767,  ..., -0.0858, -0.1008, -0.1056],
        ...,
        [-0.1012, -0.0793, -0.1059,  ..., -0.0974, -0.1025, -0.1210],
        [-0.0837, -0.0846, -0.0955,  ..., -0.1081, -0.0773, -0.0890],
        [-0.1217, -0.1046, -0.1088,  ..., -0.1200, -0.1245, -0.0926]],
       device='cuda:0')), ('1.bias', tensor([-0.0964, -0.1014, -0.1419, -0.0924, -0.1171, -0.1429, -0.1624, -0.1335,
        -0.0946, -0.1438, -0.1011, -0.1403, -0.0585, -0.1290, -0.0988, -0.0745,
        -0.0754, -0.1480, -0.0767, -0.1220, -0.1543, -0.1274, -0.0990, -0.1181,
        -0.0911, -0.1045, -0.1291, -0.1158, -0.1287, -0.1163, -0.1065, -0.1482,
        -0.1014, -0.0383, -0.0952, -0.1427, -0.1128, -0.1180, -0.0861, -0.0693,
        -0.0722, -0.0907, -0.0913, -0.1132, -0.1017, -0.1250, -0.1355, -0.0947,
        -0.0699, -0.1015, -0.1032, -0.1342, -0.0865, -0.0935, -0.1075, -0.1413,
        -0.0894, -0.1181, -0.0938, -0.1119, -0.1361, -0.0697, -0.0859, -0.1798,
        -0.0346, -0.0965, -0.1245, -0.0897, -0.1152, -0.0904, -0.1402, -0.0651,
        -0.0992, -0.1118, -0.0852, -0.1223, -0.1397, -0.1261, -0.1267, -0.1166,
        -0.0845, -0.0554, -0.1151, -0.1256, -0.1386, -0.0744, -0.1216, -0.1091,
        -0.1368, -0.1488, -0.0840, -0.0843, -0.1061, -0.0959, -0.0904, -0.0701,
        -0.0628, -0.1027, -0.0854, -0.0827, -0.1137, -0.1633, -0.0858, -0.1731,
        -0.0790, -0.0686, -0.0838, -0.0667, -0.1133, -0.1121, -0.0934, -0.1350,
        -0.1394, -0.1393, -0.1099, -0.1755, -0.0936, -0.0682, -0.1752, -0.1222,
        -0.1407, -0.0617, -0.1327, -0.1535, -0.0595, -0.0806, -0.1078, -0.1505],
       device='cuda:0')), ('3.weight', tensor([[-0.0032, -0.0434, -0.1113,  ..., -0.0101, -0.0698, -0.0124],
        [-0.1635, -0.1648, -0.1941,  ..., -0.0524, -0.1758, -0.1777],
        [-0.0943, -0.0935, -0.0678,  ..., -0.1725, -0.1101, -0.0429],
        ...,
        [-0.0747, -0.0735, -0.0517,  ..., -0.0907, -0.1262, -0.1883],
        [-0.1886, -0.1518, -0.0483,  ..., -0.1817, -0.1468, -0.1697],
        [-0.0504, -0.1257, -0.1373,  ..., -0.1118, -0.0949, -0.0647]],
       device='cuda:0')), ('3.bias', tensor([-0.0238, -0.1810, -0.0781, -0.0651, -0.1514, -0.0799, -0.0854, -0.1571,
        -0.0582, -0.0600], device='cuda:0'))])
====> Test set loss: 178.9454
Train Epoch: 0 [0/6000 (0%)]	Loss: 178.924744	BCE:178.7736	KLD:0.1502	C_loss:0.0010
Train Epoch: 0 [640/6000 (11%)]	Loss: 181.839798	BCE:181.6783	KLD:0.1603	C_loss:0.0012
Train Epoch: 0 [1280/6000 (21%)]	Loss: 180.724030	BCE:180.5979	KLD:0.1251	C_loss:0.0010
Train Epoch: 0 [1920/6000 (32%)]	Loss: 171.544922	BCE:171.1333	KLD:0.4107	C_loss:0.0009
Train Epoch: 0 [2560/6000 (43%)]	Loss: 177.812500	BCE:177.6650	KLD:0.1463	C_loss:0.0012
Train Epoch: 0 [3200/6000 (53%)]	Loss: 185.867035	BCE:185.0477	KLD:0.8178	C_loss:0.0015
Train Epoch: 0 [3840/6000 (64%)]	Loss: 185.535019	BCE:184.7981	KLD:0.7357	C_loss:0.0012
Train Epoch: 0 [4480/6000 (74%)]	Loss: 175.982452	BCE:173.2743	KLD:2.7070	C_loss:0.0012
Train Epoch: 0 [5120/6000 (85%)]	Loss: 166.736725	BCE:163.7646	KLD:2.9706	C_loss:0.0016
Train Epoch: 0 [5760/6000 (96%)]	Loss: 166.267395	BCE:161.4234	KLD:4.8429	C_loss:0.0011
====> Epoch: 0 Average loss: 175.0907	Classifier Accuracy: 87.1953
OrderedDict([('1.weight', tensor([[-0.0998, -0.1134, -0.0794,  ..., -0.1154, -0.1026, -0.1014],
        [-0.0862, -0.0895, -0.0927,  ..., -0.0858, -0.0958, -0.0790],
        [-0.0859, -0.1104, -0.0767,  ..., -0.0858, -0.1008, -0.1056],
        ...,
        [-0.1012, -0.0793, -0.1059,  ..., -0.0974, -0.1025, -0.1210],
        [-0.0837, -0.0846, -0.0955,  ..., -0.1081, -0.0773, -0.0890],
        [-0.1217, -0.1046, -0.1088,  ..., -0.1200, -0.1245, -0.0926]],
       device='cuda:0')), ('1.bias', tensor([-0.0960, -0.0966, -0.1445, -0.0931, -0.1155, -0.1456, -0.1659, -0.1281,
        -0.0907, -0.1475, -0.0963, -0.1388, -0.0470, -0.1249, -0.0987, -0.0725,
        -0.0762, -0.1549, -0.0736, -0.1176, -0.1603, -0.1283, -0.0978, -0.1143,
        -0.0836, -0.1052, -0.1387, -0.1188, -0.1323, -0.1151, -0.1128, -0.1566,
        -0.0905, -0.0283, -0.0891, -0.1397, -0.1178, -0.1208, -0.0769, -0.0635,
        -0.0645, -0.0870, -0.0862, -0.1102, -0.1011, -0.1188, -0.1498, -0.1038,
        -0.0594, -0.0992, -0.1001, -0.1386, -0.0796, -0.0877, -0.1088, -0.1431,
        -0.0927, -0.1186, -0.0941, -0.1126, -0.1415, -0.0668, -0.0812, -0.1836,
        -0.0247, -0.0931, -0.1304, -0.0839, -0.1108, -0.0900, -0.1466, -0.0615,
        -0.0951, -0.1032, -0.0733, -0.1293, -0.1492, -0.1263, -0.1257, -0.1132,
        -0.0712, -0.0407, -0.1079, -0.1260, -0.1393, -0.0753, -0.1245, -0.1027,
        -0.1291, -0.1548, -0.0798, -0.0835, -0.1095, -0.0883, -0.0843, -0.0644,
        -0.0439, -0.1000, -0.0793, -0.0797, -0.1136, -0.1659, -0.0845, -0.1790,
        -0.0758, -0.0609, -0.0762, -0.0604, -0.1120, -0.1080, -0.0892, -0.1372,
        -0.1442, -0.1413, -0.1059, -0.1852, -0.0944, -0.0632, -0.1836, -0.1238,
        -0.1458, -0.0527, -0.1402, -0.1486, -0.0397, -0.0722, -0.1043, -0.1487],
       device='cuda:0')), ('3.weight', tensor([[-0.0040, -0.0443, -0.1128,  ..., -0.0112, -0.0709, -0.0130],
        [-0.1648, -0.1655, -0.1975,  ..., -0.0508, -0.1774, -0.1805],
        [-0.0952, -0.0938, -0.0681,  ..., -0.1735, -0.1110, -0.0430],
        ...,
        [-0.0758, -0.0745, -0.0529,  ..., -0.0917, -0.1288, -0.1916],
        [-0.1899, -0.1527, -0.0481,  ..., -0.1827, -0.1479, -0.1707],
        [-0.0513, -0.1269, -0.1379,  ..., -0.1127, -0.0964, -0.0658]],
       device='cuda:0')), ('3.bias', tensor([-0.0227, -0.1920, -0.0781, -0.0553, -0.1552, -0.0878, -0.0844, -0.1655,
        -0.0512, -0.0607], device='cuda:0'))])
====> Test set loss: 161.8050
Train Epoch: 0 [0/6000 (0%)]	Loss: 167.111649	BCE:164.1847	KLD:2.9260	C_loss:0.0010
Train Epoch: 0 [640/6000 (11%)]	Loss: 159.845398	BCE:156.6070	KLD:3.2372	C_loss:0.0012
Train Epoch: 0 [1280/6000 (21%)]	Loss: 170.516052	BCE:164.7639	KLD:5.7506	C_loss:0.0015
Train Epoch: 0 [1920/6000 (32%)]	Loss: 151.253998	BCE:146.5128	KLD:4.7404	C_loss:0.0009
Train Epoch: 0 [2560/6000 (43%)]	Loss: 168.254883	BCE:162.2613	KLD:5.9924	C_loss:0.0012
Train Epoch: 0 [3200/6000 (53%)]	Loss: 147.708801	BCE:142.1619	KLD:5.5459	C_loss:0.0010
Train Epoch: 0 [3840/6000 (64%)]	Loss: 139.673706	BCE:134.5123	KLD:5.1608	C_loss:0.0006
Train Epoch: 0 [4480/6000 (74%)]	Loss: 145.926453	BCE:139.8643	KLD:6.0615	C_loss:0.0007
Train Epoch: 0 [5120/6000 (85%)]	Loss: 147.617676	BCE:141.6006	KLD:6.0159	C_loss:0.0013
Train Epoch: 0 [5760/6000 (96%)]	Loss: 149.441589	BCE:142.7438	KLD:6.6964	C_loss:0.0014
====> Epoch: 0 Average loss: 155.0702	Classifier Accuracy: 87.9543
OrderedDict([('1.weight', tensor([[-0.0998, -0.1134, -0.0794,  ..., -0.1154, -0.1026, -0.1014],
        [-0.0862, -0.0895, -0.0927,  ..., -0.0858, -0.0958, -0.0790],
        [-0.0859, -0.1104, -0.0767,  ..., -0.0858, -0.1008, -0.1056],
        ...,
        [-0.1012, -0.0793, -0.1059,  ..., -0.0974, -0.1025, -0.1210],
        [-0.0837, -0.0846, -0.0955,  ..., -0.1081, -0.0773, -0.0890],
        [-0.1217, -0.1046, -0.1088,  ..., -0.1200, -0.1245, -0.0926]],
       device='cuda:0')), ('1.bias', tensor([-0.0928, -0.0946, -0.1480, -0.0901, -0.1126, -0.1438, -0.1695, -0.1229,
        -0.0831, -0.1510, -0.0931, -0.1356, -0.0378, -0.1224, -0.0988, -0.0739,
        -0.0733, -0.1582, -0.0662, -0.1141, -0.1682, -0.1327, -0.0955, -0.1116,
        -0.0721, -0.1015, -0.1395, -0.1206, -0.1308, -0.1148, -0.1173, -0.1629,
        -0.0889, -0.0171, -0.0899, -0.1348, -0.1177, -0.1204, -0.0752, -0.0543,
        -0.0577, -0.0803, -0.0820, -0.1083, -0.0963, -0.1137, -0.1585, -0.1016,
        -0.0503, -0.0966, -0.1019, -0.1433, -0.0761, -0.0828, -0.1062, -0.1465,
        -0.0948, -0.1205, -0.0937, -0.1148, -0.1424, -0.0667, -0.0777, -0.1920,
        -0.0164, -0.0902, -0.1306, -0.0808, -0.1036, -0.0860, -0.1511, -0.0546,
        -0.0898, -0.0974, -0.0657, -0.1354, -0.1449, -0.1257, -0.1234, -0.1147,
        -0.0645, -0.0326, -0.1048, -0.1239, -0.1410, -0.0698, -0.1257, -0.0949,
        -0.1270, -0.1607, -0.0779, -0.0820, -0.1113, -0.0786, -0.0779, -0.0599,
        -0.0307, -0.0954, -0.0737, -0.0774, -0.1155, -0.1704, -0.0792, -0.1799,
        -0.0733, -0.0565, -0.0763, -0.0527, -0.1109, -0.1049, -0.0836, -0.1322,
        -0.1471, -0.1452, -0.0997, -0.1894, -0.0906, -0.0603, -0.1895, -0.1211,
        -0.1530, -0.0472, -0.1392, -0.1520, -0.0305, -0.0664, -0.0999, -0.1465],
       device='cuda:0')), ('3.weight', tensor([[-0.0011, -0.0400, -0.1093,  ..., -0.0078, -0.0677, -0.0105],
        [-0.1673, -0.1680, -0.1986,  ..., -0.0515, -0.1799, -0.1808],
        [-0.0944, -0.0929, -0.0667,  ..., -0.1735, -0.1110, -0.0416],
        ...,
        [-0.0737, -0.0725, -0.0510,  ..., -0.0899, -0.1278, -0.1911],
        [-0.1913, -0.1535, -0.0481,  ..., -0.1838, -0.1490, -0.1715],
        [-0.0516, -0.1280, -0.1386,  ..., -0.1131, -0.0973, -0.0664]],
       device='cuda:0')), ('3.bias', tensor([-0.0167, -0.1992, -0.0777, -0.0565, -0.1579, -0.0947, -0.0846, -0.1679,
        -0.0454, -0.0579], device='cuda:0'))])
====> Test set loss: 149.8872
Train Epoch: 0 [0/6000 (0%)]	Loss: 543.850647	BCE:543.7685	KLD:0.0771	C_loss:0.0051
Train Epoch: 0 [640/6000 (11%)]	Loss: 414.084106	BCE:414.0193	KLD:0.0606	C_loss:0.0042
Train Epoch: 0 [1280/6000 (21%)]	Loss: 381.799194	BCE:381.7462	KLD:0.0497	C_loss:0.0033
Train Epoch: 0 [1920/6000 (32%)]	Loss: 338.928894	BCE:338.8395	KLD:0.0869	C_loss:0.0025
Train Epoch: 0 [2560/6000 (43%)]	Loss: 288.668152	BCE:284.9999	KLD:3.6667	C_loss:0.0016
Train Epoch: 0 [3200/6000 (53%)]	Loss: 225.681808	BCE:222.8361	KLD:2.8436	C_loss:0.0021
Train Epoch: 0 [3840/6000 (64%)]	Loss: 215.466827	BCE:213.2498	KLD:2.2156	C_loss:0.0014
Train Epoch: 0 [4480/6000 (74%)]	Loss: 214.345795	BCE:212.2323	KLD:2.1118	C_loss:0.0017
Train Epoch: 0 [5120/6000 (85%)]	Loss: 208.553513	BCE:207.3586	KLD:1.1938	C_loss:0.0012
Train Epoch: 0 [5760/6000 (96%)]	Loss: 198.075104	BCE:197.3833	KLD:0.6909	C_loss:0.0008
====> Epoch: 0 Average loss: 297.1179	Classifier Accuracy: 77.3548
====> Test set loss: 197.3821
Train Epoch: 0 [0/6000 (0%)]	Loss: 205.277664	BCE:204.4252	KLD:0.8443	C_loss:0.0081
Train Epoch: 0 [640/6000 (11%)]	Loss: 212.195557	BCE:210.9641	KLD:1.2289	C_loss:0.0026
Train Epoch: 0 [1280/6000 (21%)]	Loss: 197.430298	BCE:197.2757	KLD:0.1527	C_loss:0.0019
Train Epoch: 0 [1920/6000 (32%)]	Loss: 198.148804	BCE:197.9812	KLD:0.1658	C_loss:0.0017
Train Epoch: 0 [2560/6000 (43%)]	Loss: 184.368088	BCE:184.0168	KLD:0.3498	C_loss:0.0015
Train Epoch: 0 [3200/6000 (53%)]	Loss: 185.023941	BCE:184.3877	KLD:0.6347	C_loss:0.0015
Train Epoch: 0 [3840/6000 (64%)]	Loss: 178.194763	BCE:178.0024	KLD:0.1907	C_loss:0.0017
Train Epoch: 0 [4480/6000 (74%)]	Loss: 183.673416	BCE:183.4480	KLD:0.2241	C_loss:0.0013
Train Epoch: 0 [5120/6000 (85%)]	Loss: 183.224579	BCE:182.9901	KLD:0.2332	C_loss:0.0012
Train Epoch: 0 [5760/6000 (96%)]	Loss: 181.832428	BCE:181.6163	KLD:0.2148	C_loss:0.0014
====> Epoch: 0 Average loss: 190.8853	Classifier Accuracy: 78.5073
====> Test set loss: 181.8429
Train Epoch: 0 [0/6000 (0%)]	Loss: 191.324203	BCE:191.1611	KLD:0.1613	C_loss:0.0017
Train Epoch: 0 [640/6000 (11%)]	Loss: 190.192917	BCE:189.9896	KLD:0.2021	C_loss:0.0012
Train Epoch: 0 [1280/6000 (21%)]	Loss: 185.026733	BCE:184.9197	KLD:0.1058	C_loss:0.0013
Train Epoch: 0 [1920/6000 (32%)]	Loss: 181.560989	BCE:181.4062	KLD:0.1535	C_loss:0.0013
Train Epoch: 0 [2560/6000 (43%)]	Loss: 184.473953	BCE:184.3475	KLD:0.1252	C_loss:0.0013
Train Epoch: 0 [3200/6000 (53%)]	Loss: 166.685211	BCE:166.5514	KLD:0.1329	C_loss:0.0009
Train Epoch: 0 [3840/6000 (64%)]	Loss: 178.777359	BCE:178.6542	KLD:0.1218	C_loss:0.0013
Train Epoch: 0 [4480/6000 (74%)]	Loss: 175.779358	BCE:175.6490	KLD:0.1293	C_loss:0.0011
Train Epoch: 0 [5120/6000 (85%)]	Loss: 167.646133	BCE:167.4906	KLD:0.1545	C_loss:0.0010
Train Epoch: 0 [5760/6000 (96%)]	Loss: 190.096207	BCE:189.9245	KLD:0.1704	C_loss:0.0013
====> Epoch: 0 Average loss: 182.4919	Classifier Accuracy: 85.5496
====> Test set loss: 177.3244
Train Epoch: 0 [0/6000 (0%)]	Loss: 180.873199	BCE:180.7183	KLD:0.1536	C_loss:0.0013
Train Epoch: 0 [640/6000 (11%)]	Loss: 175.630676	BCE:175.4757	KLD:0.1540	C_loss:0.0010
Train Epoch: 0 [1280/6000 (21%)]	Loss: 177.282715	BCE:177.1515	KLD:0.1301	C_loss:0.0011
Train Epoch: 0 [1920/6000 (32%)]	Loss: 182.297272	BCE:182.1309	KLD:0.1654	C_loss:0.0010
Train Epoch: 0 [2560/6000 (43%)]	Loss: 175.986145	BCE:175.8296	KLD:0.1557	C_loss:0.0009
Train Epoch: 0 [3200/6000 (53%)]	Loss: 174.763275	BCE:174.5627	KLD:0.1995	C_loss:0.0011
Train Epoch: 0 [3840/6000 (64%)]	Loss: 179.335602	BCE:179.1447	KLD:0.1899	C_loss:0.0011
Train Epoch: 0 [4480/6000 (74%)]	Loss: 174.568817	BCE:174.1874	KLD:0.3806	C_loss:0.0008
Train Epoch: 0 [5120/6000 (85%)]	Loss: 168.415161	BCE:167.2784	KLD:1.1359	C_loss:0.0008
Train Epoch: 0 [5760/6000 (96%)]	Loss: 169.567352	BCE:166.6576	KLD:2.9085	C_loss:0.0013
====> Epoch: 0 Average loss: 177.4294	Classifier Accuracy: 87.3836
====> Test set loss: 165.8774
Train Epoch: 0 [0/6000 (0%)]	Loss: 163.506592	BCE:159.3610	KLD:4.1447	C_loss:0.0010
Train Epoch: 0 [640/6000 (11%)]	Loss: 164.780304	BCE:163.5372	KLD:1.2423	C_loss:0.0008
Train Epoch: 0 [1280/6000 (21%)]	Loss: 163.009277	BCE:159.6842	KLD:3.3241	C_loss:0.0009
Train Epoch: 0 [1920/6000 (32%)]	Loss: 155.152420	BCE:150.6484	KLD:4.5031	C_loss:0.0009
Train Epoch: 0 [2560/6000 (43%)]	Loss: 158.815964	BCE:152.3002	KLD:6.5145	C_loss:0.0012
Train Epoch: 0 [3200/6000 (53%)]	Loss: 162.115707	BCE:156.4895	KLD:5.6257	C_loss:0.0006
Train Epoch: 0 [3840/6000 (64%)]	Loss: 155.083862	BCE:149.7753	KLD:5.3076	C_loss:0.0009
Train Epoch: 0 [4480/6000 (74%)]	Loss: 148.223984	BCE:142.8575	KLD:5.3656	C_loss:0.0009
Train Epoch: 0 [5120/6000 (85%)]	Loss: 165.575027	BCE:159.1857	KLD:6.3881	C_loss:0.0013
Train Epoch: 0 [5760/6000 (96%)]	Loss: 145.341141	BCE:139.3556	KLD:5.9845	C_loss:0.0011
====> Epoch: 0 Average loss: 158.9850	Classifier Accuracy: 88.0153
====> Test set loss: 148.3112
Train Epoch: 0 [0/6000 (0%)]	Loss: 543.815430	BCE:543.7332	KLD:0.0772	C_loss:0.0051
Train Epoch: 0 [640/6000 (11%)]	Loss: 409.377258	BCE:409.3131	KLD:0.0598	C_loss:0.0043
Train Epoch: 0 [1280/6000 (21%)]	Loss: 376.934296	BCE:376.8781	KLD:0.0528	C_loss:0.0034
Train Epoch: 0 [1920/6000 (32%)]	Loss: 336.541351	BCE:336.4662	KLD:0.0722	C_loss:0.0029
Train Epoch: 0 [2560/6000 (43%)]	Loss: 277.613007	BCE:275.0673	KLD:2.5436	C_loss:0.0021
Train Epoch: 0 [3200/6000 (53%)]	Loss: 232.296860	BCE:230.8049	KLD:1.4904	C_loss:0.0016
Train Epoch: 0 [3840/6000 (64%)]	Loss: 226.517578	BCE:224.8389	KLD:1.6774	C_loss:0.0013
Train Epoch: 0 [4480/6000 (74%)]	Loss: 202.642410	BCE:202.0141	KLD:0.6267	C_loss:0.0016
Train Epoch: 0 [5120/6000 (85%)]	Loss: 201.881729	BCE:201.2421	KLD:0.6386	C_loss:0.0010
Train Epoch: 0 [5760/6000 (96%)]	Loss: 192.800323	BCE:192.2870	KLD:0.5119	C_loss:0.0014
====> Epoch: 0 Average loss: 294.1629	Classifier Accuracy: 75.7148
====> Test set loss: 192.8433
Train Epoch: 0 [0/6000 (0%)]	Loss: 197.067245	BCE:196.6130	KLD:0.4456	C_loss:0.0086
Train Epoch: 0 [640/6000 (11%)]	Loss: 196.812195	BCE:196.5245	KLD:0.2852	C_loss:0.0025
Train Epoch: 0 [1280/6000 (21%)]	Loss: 184.159042	BCE:183.8118	KLD:0.3450	C_loss:0.0023
Train Epoch: 0 [1920/6000 (32%)]	Loss: 181.529785	BCE:181.2836	KLD:0.2441	C_loss:0.0020
Train Epoch: 0 [2560/6000 (43%)]	Loss: 191.326614	BCE:191.1757	KLD:0.1493	C_loss:0.0017
Train Epoch: 0 [3200/6000 (53%)]	Loss: 193.800095	BCE:193.4706	KLD:0.3278	C_loss:0.0017
Train Epoch: 0 [3840/6000 (64%)]	Loss: 188.215027	BCE:187.8754	KLD:0.3382	C_loss:0.0015
Train Epoch: 0 [4480/6000 (74%)]	Loss: 185.859772	BCE:185.5635	KLD:0.2948	C_loss:0.0015
Train Epoch: 0 [5120/6000 (85%)]	Loss: 176.524048	BCE:176.3575	KLD:0.1653	C_loss:0.0012
Train Epoch: 0 [5760/6000 (96%)]	Loss: 173.895157	BCE:173.6240	KLD:0.2700	C_loss:0.0012
====> Epoch: 0 Average loss: 188.7511	Classifier Accuracy: 79.4215
====> Test set loss: 183.0714
Train Epoch: 0 [0/6000 (0%)]	Loss: 175.241791	BCE:174.9026	KLD:0.3380	C_loss:0.0012
Train Epoch: 0 [640/6000 (11%)]	Loss: 188.196320	BCE:188.1141	KLD:0.0810	C_loss:0.0012
Train Epoch: 0 [1280/6000 (21%)]	Loss: 185.009308	BCE:184.9400	KLD:0.0680	C_loss:0.0013
Train Epoch: 0 [1920/6000 (32%)]	Loss: 175.493637	BCE:175.4125	KLD:0.0801	C_loss:0.0011
Train Epoch: 0 [2560/6000 (43%)]	Loss: 179.217789	BCE:179.0861	KLD:0.1303	C_loss:0.0014
Train Epoch: 0 [3200/6000 (53%)]	Loss: 189.142181	BCE:188.8942	KLD:0.2463	C_loss:0.0017
Train Epoch: 0 [3840/6000 (64%)]	Loss: 178.508972	BCE:178.3215	KLD:0.1863	C_loss:0.0012
Train Epoch: 0 [4480/6000 (74%)]	Loss: 178.299957	BCE:178.1548	KLD:0.1438	C_loss:0.0014
Train Epoch: 0 [5120/6000 (85%)]	Loss: 173.486603	BCE:173.3965	KLD:0.0887	C_loss:0.0014
Train Epoch: 0 [5760/6000 (96%)]	Loss: 170.723541	BCE:170.4900	KLD:0.2328	C_loss:0.0008
====> Epoch: 0 Average loss: 180.9415	Classifier Accuracy: 85.2227
====> Test set loss: 174.5949
Train Epoch: 0 [0/6000 (0%)]	Loss: 181.929092	BCE:181.5561	KLD:0.3716	C_loss:0.0014
Train Epoch: 0 [640/6000 (11%)]	Loss: 211.918808	BCE:211.5641	KLD:0.3534	C_loss:0.0013
Train Epoch: 0 [1280/6000 (21%)]	Loss: 167.076019	BCE:166.4188	KLD:0.6562	C_loss:0.0010
Train Epoch: 0 [1920/6000 (32%)]	Loss: 173.653519	BCE:170.8191	KLD:2.8335	C_loss:0.0009
Train Epoch: 0 [2560/6000 (43%)]	Loss: 171.250534	BCE:168.1727	KLD:3.0768	C_loss:0.0010
Train Epoch: 0 [3200/6000 (53%)]	Loss: 169.860413	BCE:165.8170	KLD:4.0421	C_loss:0.0013
Train Epoch: 0 [3840/6000 (64%)]	Loss: 152.004044	BCE:147.7824	KLD:4.2209	C_loss:0.0007
Train Epoch: 0 [4480/6000 (74%)]	Loss: 158.941437	BCE:152.0663	KLD:6.8739	C_loss:0.0012
Train Epoch: 0 [5120/6000 (85%)]	Loss: 149.618927	BCE:142.9991	KLD:6.6189	C_loss:0.0009
Train Epoch: 0 [5760/6000 (96%)]	Loss: 157.407516	BCE:151.8483	KLD:5.5582	C_loss:0.0011
====> Epoch: 0 Average loss: 167.6299	Classifier Accuracy: 88.0541
====> Test set loss: 153.8254
Train Epoch: 0 [0/6000 (0%)]	Loss: 158.721268	BCE:153.0890	KLD:5.6314	C_loss:0.0009
Train Epoch: 0 [640/6000 (11%)]	Loss: 161.991302	BCE:158.0474	KLD:3.9429	C_loss:0.0010
Train Epoch: 0 [1280/6000 (21%)]	Loss: 156.195801	BCE:152.3196	KLD:3.8750	C_loss:0.0012
Train Epoch: 0 [1920/6000 (32%)]	Loss: 155.454697	BCE:150.0824	KLD:5.3713	C_loss:0.0010
Train Epoch: 0 [2560/6000 (43%)]	Loss: 143.974121	BCE:138.1685	KLD:5.8047	C_loss:0.0009
Train Epoch: 0 [3200/6000 (53%)]	Loss: 140.871368	BCE:135.4728	KLD:5.3978	C_loss:0.0008
Train Epoch: 0 [3840/6000 (64%)]	Loss: 149.693390	BCE:144.1910	KLD:5.5015	C_loss:0.0009
Train Epoch: 0 [4480/6000 (74%)]	Loss: 146.990707	BCE:140.4568	KLD:6.5330	C_loss:0.0008
Train Epoch: 0 [5120/6000 (85%)]	Loss: 153.016418	BCE:146.6570	KLD:6.3583	C_loss:0.0010
Train Epoch: 0 [5760/6000 (96%)]	Loss: 151.442810	BCE:145.1939	KLD:6.2482	C_loss:0.0007
====> Epoch: 0 Average loss: 154.0704	Classifier Accuracy: 87.8435
====> Test set loss: 146.3975
